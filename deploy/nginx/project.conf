#定义企业级日志格式 (main)
log_format enhanced_main '$remote_addr - $remote_user [$time_local] "$request" '
                '$status $body_bytes_sent "$http_referer" '
                '"$http_user_agent" "$http_x_forwarded_for" '
                'rt=$request_time uct="$upstream_connect_time" uat="$upstream_addr" '
                'rid="$http_x_request_id"'; # 顺便把我们之前的 Request ID 也打进去
# 定义后端服务池 (Upstream)
upstream backend_servers {
    # 轮询 (Round Robin) 是默认策略
    least_conn;
    server api:8000 max_fails=3 fail_timeout=30s;
    keepalive 32;

    # DBA 视角：如果需要会话保持，可以开启 ip_hash
    # ip_hash; 
}

server {
    listen 80;
    server_name localhost;
# 2. 启用该格式的日志
    access_log /var/log/nginx/access.log enhanced_main;
    error_log /var/log/nginx/error.log warn;

    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
        # 核心：如果找不到资源，统一指向 index.html，让 React Router 接管路由
        try_files $uri $uri/ /index.html;
    }

    # 反向代理：解决跨域问题，将 /api 开头的请求转发到后端
    location /api/ {
        # 1. 在入口处生成或透传 Request ID
        proxy_set_header X-Request-ID $request_id;
        
        # 2. 基础透传
        proxy_pass http://api:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # 3. 路径重写
        #3rewrite ^/api/(.*)$ /$1 break;

        # 4. 针对 LLM 流式响应的优化 (Ollama 必备)
        proxy_http_version 1.1;       # 必须用 HTTP/1.1 才能支持长连接
        proxy_set_header Connection ""; 
        proxy_buffering off;          # 关闭缓冲区！否则 Nginx 会攒够一波数据才发给前端，流式效果会卡顿
        proxy_cache off;              # AI 响应通常不缓存
    }
}