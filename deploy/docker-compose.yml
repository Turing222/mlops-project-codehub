#通用的日志模板
x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"
services:

  postgres:
    image: pgvector/pgvector:0.8.1-pg17-bookworm
    container_name: pgvector-17-stable
    env_file:
      - ../.env
    # 1. 在服务内挂载卷
    volumes:
      - pg_data_v17:/var/lib/postgresql/data
      - ../logs/postgres_logs:/var/log/postgresql
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 1024M
          #共享缓冲区 工作内存 维护工作内存 有效缓存预测 最大连接数
    command: >
      postgres -c shared_buffers=256MB   -c work_mem=32MB   -c maintenance_work_mem=128MB  -c effective_cache_size=768MB -c max_connections=200 -c logging_collector=on
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7.4-alpine
    env_file:
      - ../.env # 确保路径正确，读取刚才定义的变量
    deploy:
      resources:
        limits:
          memory: 512M
    logging: *default-logging
    # 通过 --requirepass 参数启用密码
    command: >
      redis-server  --maxmemory 384mb  --maxmemory-policy allkeys-lru  --requirepass "${REDIS_PASSWORD}"
  api:
    image: ai-tutor-backend:v1

    #开发阶段日志不挂载
    volumes:
      # 将容器内的 /app/logs 映射到当前目录下的 logs 文件夹
      - ../logs/backend:/app/logs/backend
    # 限制 Docker 自身收集的控制台日志大小，防止撑爆磁盘
    #只管控制台日志
    logging: *default-logging
    user: "${CURRENT_UID}:${CURRENT_GID}"
    # 模拟 2026 生产环境 Python 3.11 优化环境
    env_file:
      - ../.env
    environment:
      - PYTHONMALLOC=debug # 生产环境建议设为 default
      - WEB_CONCURRENCY=1 # 充分利用 1.5GB 内存，启动 4 个 Worker  Worker Process（工作进程）
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
        reservations:
          # 预留内存，确保容器不会因为内存碎片化启动失败
          memory: 128M
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    healthcheck:
      # 1. 确保路径与你的路由完全一致
      # 2. 使用 python3 确保兼容性
      test: [ "CMD-SHELL", "python3 -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8000/api/v1/health_check/live\", timeout=5)' || exit 1" ]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s # 考虑到 FastAPI 启动和数据库连接，给 10 秒缓冲
  nginx:
    image: nginx:stable-alpine
    logging: *default-logging
    volumes:
      # 挂载前端打包后的代码
      - ../frontend/apps/admin/dist:/usr/share/nginx/html
      # 引用你之前创建的那个配置文件
      - ./nginx/project.conf:/etc/nginx/conf.d/default.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ../logs/nginx:/var/log/nginx # 使用具名卷挂载日志
    depends_on:
      api:
        condition: service_healthy
    ports:
      - "80:80"
      - "443:443" # 映射 HTTPS

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    profiles: [ "monitoring" ] # 打上标签
    logging: *default-logging
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      # 限制数据只保留 7 天，防止硬盘撑爆
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=7d'
    deploy:
      resources:
        limits:
          memory: 256M # 强制限制内存，防止它在数据多时疯狂扩容

  grafana:
    image: grafana/grafana-oss:latest
    container_name: grafana
    profiles: [ "monitoring" ] # 打上标签
    logging: *default-logging
    environment:
      - GF_ANALYTICS_REPORTING_ENABLED=false # 禁用统计上报
      - GF_AUTH_ANONYMOUS_ENABLED=true # 调试阶段开启匿名访问（可选）
    deploy:
      resources:
        limits:
          memory: 256M

volumes:
  pg_data_v17:
    name: prod_db_volume
